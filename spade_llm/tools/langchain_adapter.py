"""LangChain tools adapter for SPADE_LLM."""

import json
import asyncio
import logging
from typing import Dict, Any, Optional

from .llm_tool import LLMTool

logger = logging.getLogger("spade_llm.tools.langchain")


class LangChainToolAdapter(LLMTool):
    """
    Adapter for using LangChain tools within SPADE_LLM.
    
    This adapter wraps LangChain tools to make them compatible with the
    SPADE_LLM tooling system, allowing seamless integration of the
    extensive LangChain tool ecosystem.
    """
    
    def __init__(self, langchain_tool):
        """
        Initialize a new LangChain tool adapter.
        
        Args:
            langchain_tool: A LangChain tool instance.
        """
        self.lc_tool = langchain_tool
        
        # Extract information from the LangChain tool
        name = getattr(langchain_tool, "name", "unknown_tool")
        description = getattr(langchain_tool, "description", 
                             "No description available for this tool.")
        
        # Convert the parameters schema if it exists
        parameters = self._convert_parameters_schema(langchain_tool)
        
        super().__init__(
            name=name,
            description=description,
            parameters=parameters,
            func=self._execute_langchain_tool
        )
        
        # Store expected parameter format
        self._expected_param = self._get_expected_parameter_name()
    
    def _convert_parameters_schema(self, tool) -> Dict[str, Any]:
        """
        Convert LangChain tool parameters schema to OpenAI format.
        
        Args:
            tool: The LangChain tool.
            
        Returns:
            A JSON Schema object compatible with OpenAI's function calling.
        """
        # If the tool has a schema, use it
        if hasattr(tool, 'args_schema'):
            try:
                # Handle both pydantic v1 and v2
                if hasattr(tool.args_schema, 'schema'):
                    # Pydantic v1
                    schema = tool.args_schema.schema()
                    
                    # Ensure it's a proper JSON Schema object
                    if 'properties' not in schema:
                        schema = {
                            "type": "object",
                            "properties": schema,
                            "required": []
                        }
                    return schema
                else:
                    # For pydantic v2 or other schemas
                    logger.warning(f"Unsupported schema type for tool {tool.name}. Using default schema.")
            except Exception as e:
                logger.error(f"Error converting schema for tool {tool.name}: {e}")
        
        # Default schema for tools without a defined schema
        return {
            "type": "object",
            "properties": {
                "input": {
                    "type": "string",
                    "description": f"Input for the {tool.name} tool"
                }
            },
            "required": ["input"]
        }
    
    def _get_expected_parameter_name(self) -> str:
        """
        Determine the expected parameter name for the LangChain tool.
        
        Many LangChain tools expect a single parameter named 'input',
        but this can be customized by looking at the schema.
        
        Returns:
            The name of the main input parameter.
        """
        # Try to determine from schema properties
        if hasattr(self.lc_tool, 'args_schema'):
            # For newer LangChain tools, check the schema
            if hasattr(self.lc_tool.args_schema, 'schema'):
                schema = self.lc_tool.args_schema.schema()
                if 'properties' in schema and len(schema['properties']) == 1:
                    # If there's only one property, use its name
                    return next(iter(schema['properties']))
        
        # Default to 'input' for standard LangChain tools
        return "input"
            
    async def _execute_langchain_tool(self, **kwargs) -> Any:
        """
        Execute the LangChain tool.
        
        Args:
            **kwargs: Arguments to pass to the LangChain tool.
            
        Returns:
            The result of the tool execution.
        """
        try:
            # Convert OpenAI-style parameters to LangChain format
            lc_args = self._transform_parameters(**kwargs)
            
            logger.debug(f"Executing {self.name} with transformed params: {lc_args}")
            
            # Determine if the tool is async
            if hasattr(self.lc_tool, '_acall') or hasattr(self.lc_tool, 'acall'):
                acall = getattr(self.lc_tool, '_acall', None) or getattr(self.lc_tool, 'acall')
                return await acall(**lc_args)
            elif hasattr(self.lc_tool, '_call') or hasattr(self.lc_tool, 'call'):
                call = getattr(self.lc_tool, '_call', None) or getattr(self.lc_tool, 'call')
                # Execute in a thread to avoid blocking
                return await asyncio.to_thread(call, **lc_args)
            elif hasattr(self.lc_tool, 'run') or hasattr(self.lc_tool, '__call__'):
                # Try direct invocation as a last resort
                func = getattr(self.lc_tool, 'run', None) or self.lc_tool
                
                # Check if it's a direct string input tool (most common case)
                if len(kwargs) == 1 and self._expected_param in lc_args:
                    # For tools that expect a direct string argument
                    return await asyncio.to_thread(func, lc_args[self._expected_param])
                else:
                    return await asyncio.to_thread(func, **lc_args)
        except Exception as e:
            logger.error(f"Error executing LangChain tool {self.name}: {e}")
            return {"error": str(e)}
    
    def _transform_parameters(self, **kwargs) -> Dict[str, Any]:
        """
        Transform parameters from OpenAI format to LangChain format.
        
        For example, transforms {'query': 'something'} to {'input': 'something'}
        if the LangChain tool expects an 'input' parameter.
        
        Args:
            **kwargs: Parameters in OpenAI format.
            
        Returns:
            Parameters in LangChain format.
        """
        # For DuckDuckGo search with 'query' parameter
        if self.name == "duckduckgo-search" and "query" in kwargs:
            return {self._expected_param: kwargs["query"]}
        
        # For Wikipedia with 'query' parameter
        if self.name == "wikipedia-query" and "query" in kwargs:
            return {self._expected_param: kwargs["query"]}
        
        # For simple tools expecting just one parameter
        if len(kwargs) == 1 and len(self.parameters.get('properties', {})) == 1:
            # Take whatever value is provided and use the expected parameter name
            return {self._expected_param: next(iter(kwargs.values()))}
        
        # For tools with complex parameter mapping, we'd need custom logic here
        # For now, return as-is and hope parameter names match
        return kwargs
